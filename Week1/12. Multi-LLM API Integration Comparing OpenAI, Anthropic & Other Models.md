# Ghi chú học tập: Lab 2 - Tuần 1, Ngày 3 - Điều phối và gọi API nhiều mô hình ngôn ngữ lớn (LLMs)

## Mục tiêu bài học
- Thực hành gọi API của nhiều mô hình ngôn ngữ lớn (LLMs) khác nhau.
- Tìm hiểu cách sử dụng các mô hình để tạo câu hỏi và trả lời câu hỏi, đồng thời so sánh kết quả.
- Áp dụng các mẫu thiết kế (design patterns) để điều phối giữa các mô hình.
- Khuyến khích thử nghiệm, gỡ lỗi và đóng góp vào kho mã nguồn cộng đồng.

## Nội dung chính

### 1. Phương pháp giảng dạy và học tập
- **Cách tiếp cận**:
  - Giảng viên không tập trung gõ mã trực tiếp mà giải thích các ô mã (cells), chạy chúng và kiểm tra kết quả.
  - Đề xuất: Xem giải thích, sau đó tự chạy mã, thêm câu lệnh in (print statements), thay đổi và thử nghiệm.
- **Khuyến khích thử nghiệm**:
  - Thay đổi mã, thêm các câu lệnh để kiểm tra kết quả.
  - Tự do thử nghiệm với các mô hình khác nhau để so sánh.
- **Đóng góp cộng đồng**:
  - Lưu các thay đổi trong thư mục `Community Contributions` và gửi pull request (PR) để chia sẻ với học viên khác.
  - Ví dụ: Khóa học trước đã nhận được hàng trăm PR từ học viên, mang lại giá trị lớn.
- **Xây dựng danh mục cá nhân**:
  - Tạo kho mã nguồn cá nhân trên GitHub để lưu trữ dự án.
  - Chia sẻ dự án trên LinkedIn, tag giảng viên để nhận phản hồi và tăng khả năng tiếp cận với nhà tuyển dụng hoặc khách hàng.

### 2. Thiết lập môi trường
- **Tải biến môi trường (Environment Variables)**:
  - Sử dụng thư viện để tải biến môi trường từ tệp `.env`.
  - Cài đặt `override=True` để tránh xung đột với các biến môi trường hiện có.
  ```python
  from dotenv import load_dotenv
  load_dotenv(override=True)
  ```
- **Các API được thiết lập**:
  - OpenAI, Anthropic, Google Gemini, DeepSeek, Grok.
  - **Lưu ý về chi phí**:
    - **Grok**: Chỉ trả phí theo mức sử dụng, rất rẻ.
    - **DeepSeek**: Yêu cầu nạp trước $2, sau đó trừ dần.
    - **Gemini**: Miễn phí trong giới hạn sử dụng.
    - **Anthropic và OpenAI**: Yêu cầu nạp trước $5 (theo thông tin tại thời điểm bài giảng).
  - Kiểm tra khóa API (API keys) bằng cách in ra để đảm bảo chúng hợp lệ:
  ```python
  print(os.environ.get('OPENAI_API_KEY'))  # Kiểm tra khóa API
  ```

### 3. Thực hành gọi API và điều phối mô hình
- **Mục tiêu**:
  - Tạo một câu hỏi khó, mang tính thách thức để đánh giá trí thông minh của các mô hình.
  - Gọi nhiều mô hình để trả lời câu hỏi này và so sánh kết quả.
- **Quy trình**:
  1. Tạo câu hỏi bằng GPT-4 Mini.
  2. Gửi câu hỏi này cho các mô hình khác nhau.
  3. Lưu trữ và hiển thị câu trả lời để so sánh.

#### 3.1. Tạo câu hỏi bằng GPT-4 Mini
- **Yêu cầu**:
  - Tạo một câu hỏi phức tạp, tinh tế (nuanced) để đánh giá trí thông minh của LLMs.
  - Chỉ trả về câu hỏi, không giải thích.
- **Mã nguồn**:
  ```python
  request = "Please come up with a challenging, nuanced question that I can ask a number of LLMs to evaluate their intelligence. Please answer only with the question. No explanation."
  messages = [{"role": "user", "content": request}]
  print(messages)  # In ra để kiểm tra: [{'role': 'user', 'content': '...'}]
  ```
- **Gọi API OpenAI**:
  - Sử dụng thư viện Python của OpenAI để gọi GPT-4 Mini.
  ```python
  from openai import OpenAI
  client = OpenAI()
  response = client.chat.completions.create(
      model="gpt-4-mini",
      messages=messages
  )
  question = response.choices[0].message.content
  print(question)
  ```
- **Kết quả**:
  - Câu hỏi: *Phân tích các hàm ý đạo đức của việc sử dụng AI trong cảnh sát dự đoán (predictive policing), xem xét các yếu tố như thiên vị (bias), trách nhiệm giải trình (accountability) và tác động xã hội (societal impact).*  
  - Đây là một câu hỏi khó, yêu cầu phân tích sâu về đạo đức và xã hội.

#### 3.2. Gửi câu hỏi cho GPT-4 Mini
- **Mục đích**: Sử dụng GPT-4 Mini để trả lời chính câu hỏi mà nó tạo ra.
- **Mã nguồn**:
  ```python
  competitors = []  # Danh sách lưu tên các mô hình
  answers = []      # Danh sách lưu câu trả lời
  model_name = "gpt-4-mini"
  messages = [{"role": "user", "content": question}]
  response = client.chat.completions.create(
      model=model_name,
      messages=messages
  )
  answer = response.choices[0].message.content
  from IPython.display import display, Markdown
  display(Markdown(answer))  # Hiển thị câu trả lời ở định dạng Markdown
  competitors.append(model_name)
  answers.append(answer)
  ```
- **Kết quả**:
  - Câu trả lời được hiển thị dưới dạng Markdown, bao gồm các phần rõ ràng như phân tích thiên vị, trách nhiệm giải trình, tác động xã hội và kết luận.
  - Câu trả lời chi tiết, có cấu trúc tốt, thể hiện khả năng xử lý vấn đề phức tạp của GPT-4 Mini.

### 4. Ghi chú thêm
- **Không cần tin nhắn hệ thống (system message)**:
  - Tin nhắn hệ thống (ví dụ: "Bạn là một trợ lý hữu ích") là tùy chọn.
  - Trong trường hợp yêu cầu đơn giản, chỉ cần tin nhắn người dùng (user message) là đủ.
- **Tối ưu hóa học tập**:
  - Thử nghiệm với các mô hình khác (Claude, Gemini, DeepSeek, Grok).
  - Thêm câu lệnh in để kiểm tra dữ liệu trung gian.
  - Gặp lỗi là cơ hội học tập qua gỡ lỗi (debugging).
- **Đóng góp cộng đồng**:
  - Gửi pull request với các thử nghiệm của bạn để chia sẻ với cộng đồng.
  - Tạo danh mục cá nhân trên GitHub và chia sẻ trên LinkedIn để tăng khả năng kết nối.

## Kết luận
- Lab 2 tập trung vào việc gọi API của GPT-4 Mini để tạo và trả lời câu hỏi phức tạp.
- Quy trình điều phối bao gồm tạo câu hỏi, gửi câu hỏi cho mô hình, và hiển thị kết quả dưới dạng Markdown.
- Khuyến khích thử nghiệm, gỡ lỗi và đóng góp vào kho mã nguồn để học hỏi và chia sẻ.

---

*Ghi chú được định dạng chuẩn Markdown, tối ưu hóa cho Obsidian, với cấu trúc rõ ràng và dễ liên kết chéo.*