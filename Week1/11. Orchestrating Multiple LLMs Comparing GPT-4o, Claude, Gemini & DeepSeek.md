# Ghi chú học tập: Ngày 3 - Điều phối giữa các mô hình ngôn ngữ lớn (LLMs)

## Mục tiêu bài học
- Hiểu cách điều phối và gọi nhiều mô hình ngôn ngữ lớn (LLMs) trong một quy trình làm việc có tính agent (agentic workflow).
- Thực hành viết mã để tương tác với cả API trả phí và mô hình mã nguồn mở (open-source models).
- Linh hoạt trong việc chọn mô hình và triển khai chúng trên đám mây hoặc cục bộ.
- Tìm hiểu về các mô hình ngôn ngữ lớn phổ biến, cách so sánh hiệu suất và chi phí của chúng.

## Nội dung chính

### 1. Tổng quan về điều phối LLMs
- **Mục đích**: Tích hợp nhiều mô hình ngôn ngữ lớn vào một quy trình làm việc để tận dụng ưu điểm của từng mô hình.
- **Linh hoạt trong lựa chọn mô hình**:
  - Có thể sử dụng mô hình trả phí (closed-source) hoặc mã nguồn mở (open-source).
  - Có thể chạy mô hình trên đám mây (cloud) hoặc cục bộ (locally).
  - Không cần chi phí nếu sử dụng mô hình mã nguồn mở cục bộ, nhưng hiệu suất có thể khác so với mô hình trả phí.
- **Tài liệu tham khảo**:
  - Khóa học kỹ thuật LLM (LLM engineering course) cung cấp thông tin chi tiết về việc chọn và triển khai mô hình.
  - Hướng dẫn bổ sung có trong tài liệu khóa học (guides) và kho mã nguồn (GitHub repository).

### 2. Các mô hình ngôn ngữ lớn được sử dụng
Dưới đây là danh sách các mô hình chính được giới thiệu:

#### 2.1. OpenAI
- **GPT-4 Mini**:
  - Mô hình nổi tiếng nhất, được sử dụng trong các bài thực hành trước.
  - Phù hợp cho nhiều tác vụ, hiệu suất cao.
- **GPT-4**:
  - Phiên bản mạnh hơn của GPT-4 Mini, nhưng chi phí cao hơn.
- **Mô hình suy luận (Reasoning Models)**:
  - Ví dụ: o1, o3-mini.
  - Được huấn luyện để suy luận từng bước (step-by-step reasoning), cải thiện kết quả đầu ra.
  - Không tập trung trong khóa học này, nhưng có thể được đề cập.

#### 2.2. Anthropic
- **Claude 3.7 Sonnet**:
  - Mô hình chính được sử dụng từ Anthropic.
  - Đối thủ cạnh tranh trực tiếp với GPT-4.
- **Claude 3 Haiku**:
  - Phiên bản chi phí thấp hơn, phù hợp cho các tác vụ đơn giản.

#### 2.3. Google
- **Gemini 2.0 Flash**:
  - Miễn phí trong giới hạn sử dụng nhất định.
  - Phù hợp cho người muốn thử nghiệm mô hình không tốn chi phí.
- **Gemini Pro**:
  - Phiên bản nâng cao, nhưng khóa học sẽ tập trung vào Flash.

#### 2.4. DeepSeek
- **DeepSeek V3 và R1**:
  - Đột phá nhờ chi phí huấn luyện thấp (30 lần thấp hơn so với GPT-4) nhưng hiệu suất gần tương đương.
  - Mô hình lớn có 671 tỷ tham số, không thể chạy trên máy tính cá nhân.
  - Phiên bản thu nhỏ (distilled versions) dựa trên Llama và Qwen, miễn phí và phù hợp để chạy cục bộ.

#### 2.5. Grok
- **Grok (xAI)**:
  - Mô hình từ xAI, không nhầm lẫn với Groq (dưới đây).
  - Có thể được sử dụng trong các bài thực hành sau.
- **Groq**:
  - Nền tảng tối ưu hóa việc chạy các mô hình mã nguồn mở như Llama 3.3 (70 tỷ tham số) với tốc độ cao và chi phí thấp.
  - Hỗ trợ nhiều mô hình mã nguồn mở, bao gồm các phiên bản DeepSeek.

#### 2.6. Ollama
- **Ollama**:
  - Nền tảng chạy mô hình mã nguồn mở cục bộ, cung cấp API tương tự như OpenAI.
  - Sử dụng thư viện `llama.cpp` (C++) để tối ưu hóa hiệu suất.
  - Phù hợp cho các tác vụ không cần kết nối mạng.

### 3. Tài nguyên so sánh mô hình
- **Vellum Leaderboard**:
  - Website so sánh các mô hình closed-source và open-source.
  - Cung cấp thông tin về:
    - Chi phí (cost).
    - Kích thước cửa sổ ngữ cảnh (context window size).
    - Hiệu suất trên các bài kiểm tra chuẩn (benchmarks).
  - Đề xuất: Lưu bookmark để tham khảo khi chọn mô hình.

### 4. Hướng dẫn thực hành
- **Mục tiêu thực hành**:
  - Gọi API của các mô hình trả phí và mã nguồn mở.
  - Chạy mô hình cục bộ với Ollama hoặc trên đám mây với Groq.
  - Thử nghiệm thay đổi mô hình để so sánh kết quả.
- **Gợi ý**:
  - Sử dụng mã nguồn từ giảng viên làm mẫu, sau đó áp dụng cho các mô hình khác.
  - Nếu gặp lỗi, xem đây là cơ hội học tập qua gỡ lỗi (debugging).
  - Tham khảo tài liệu khóa học hoặc liên hệ giảng viên qua LinkedIn/email nếu cần hỗ trợ.

### 5. Kỹ thuật làm việc với LLMs
- **Sử dụng nhiều mô hình để kiểm tra chéo**:
  - Hỏi cùng một câu hỏi cho ChatGPT và Claude, sau đó so sánh câu trả lời.
  - Sử dụng mô hình thứ hai để đánh giá (evaluate) câu trả lời của mô hình đầu tiên.
  - Kỹ thuật này tương tự mô hình "evaluator optimizer" đã học trước đó.
- **Tận dụng tài liệu khóa học**:
  - Tài liệu chính: Videos, hướng dẫn, kho mã nguồn trên GitHub.
  - Cập nhật thường xuyên để bao gồm các mô hình mới nhất.

### 6. Ghi chú thêm
- **Khả năng gặp lỗi**:
  - Lỗi là bình thường trong quá trình học tập.
  - Gỡ lỗi (debugging) là cơ hội để học sâu hơn.
- **Tài liệu bổ sung**:
  - Xem hướng dẫn trong khóa học hoặc khóa học kỹ thuật LLM để hiểu rõ hơn về các khái niệm như suy luận (inference), triển khai mô hình, v.v.
- **Liên hệ hỗ trợ**:
  - Email hoặc LinkedIn của giảng viên.
  - Thử hỏi ChatGPT hoặc Claude để nhận câu trả lời nhanh khi gặp vấn đề.

## Kết luận
- Ngày 3 tập trung vào thực hành gọi và điều phối nhiều mô hình ngôn ngữ lớn, từ trả phí đến mã nguồn mở.
- Linh hoạt trong việc chọn mô hình và nền tảng (cloud hoặc local).
- Sử dụng các tài nguyên như Vellum Leaderboard để so sánh và chọn mô hình phù hợp.
- Thực hành là chìa khóa, và gỡ lỗi là cơ hội để học hỏi.

---

*Ghi chú được tối ưu hóa để lưu trữ và tra cứu trong Obsidian, với cấu trúc rõ ràng và dễ liên kết chéo.*